<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Experience</title>
</head>
<body>
    <h1>Research Experience</h1>

    <h3>University of Alberta, Alberta Machine Intelligence Institute (AMII) – Edmonton, Canada</h3>
    <p><strong>Machine Learning Research Intern</strong> (March 2024 - Present)</p>
    <ul>
        <li><strong>ProtoECGNet:</strong> Worked under the supervision of Dr. Russ Greiner, Dr. Padma Kaul, and Dr. Sunil Kalmady Vasu. Developed ProtoECGNet, a prototype-based interpretable diagnostic deep learning model for electrocardiograms (ECGs). The model provides low-level statement code predictions along with the final diagnostic labels.</li>
        <li><strong>Explainability:</strong> Integrated LLMs with RAG to provide semantic explanations of diagnoses, similar to human cardiovascular experts.</li>
        <li><strong>Impact:</strong> Two variations of ProtoECGNet ranked in the top 10 in IEEE Computing in Cardiology Conference.</li>
    </ul>

    <h3>Information Processing and Transmission Lab – Islamabad, Pakistan</h3>
    <p><strong>Machine Learning Research Intern</strong> (March 2024 - Present)</p>
    <ul>
        <li><strong>Work:</strong> Developing domain-specific LLMs for 6G networks, focusing on network modeling, channel state prediction, and dynamic spectrum allocation. Achieved 94.24% optimal spectral efficiency and 86.51% optimal energy efficiency in D2D wireless networks.</li>
        <li><strong>Submitted:</strong> The work has been submitted to the IEEE International Conference on Communications (ICC) 2024.</li>
    </ul>

    <h3>Deep Learning Lab, National Centre of Artificial Intelligence (NCAI) – H-12, Islamabad</h3>
    <p><strong>Research Intern</strong> (June 2023 - May 2024)</p>
    <ul>
        <li><strong>QuickFormer - GPT for Edge Devices:</strong> Proposed and implemented a faster transformer architecture named QuickFormer, achieving an 8x speed-up during training and inference, and a 10x reduced memory footprint.</li>
        <li><strong>EEGFormer:</strong> Collaborated with a PhD student to design and implement a custom transformer architecture, EEGFormer, for epilepsy detection with 85% accuracy and an F1 score of 0.71.</li>
    </ul>

    <h3>High Performance Computing Lab, NUST – H-12, Islamabad</h3>
    <p><strong>Machine Learning Research Intern</strong> (June 2022 - September 2022)</p>
    <ul>
        <li><strong>Intelligent Parking Management:</strong> Designed and implemented an IoT-enabled parking management framework, reducing average parking search times by 35% compared to the unintelligent algorithm.</li>
    </ul>

    <h3>Optical Networks and Technologies Lab (ONT), NUST – H-12, Islamabad</h3>
    <p><strong>Machine Learning Research Intern</strong> (March 2023 - January 2024)</p>
    <ul>
        <li><strong>Virtual Network Embedding:</strong> Developed a simulation for an integrated network for 6G, with a focus on free-space optical communication and auto-encoder-based signal reconstruction.</li>
        <li><strong>Optimal BBU Placement:</strong> Extended the PhD student's work on optimal Baseband Unit (BBU) placement, implementing an algorithm for 5G networks in online traffic scenarios.</li>
    </ul>

    <p><a href="index.html">Back to Main Page</a></p>
</body>
</html>
